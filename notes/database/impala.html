<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Impala related notes</title>
<!-- 2013-07-05 Fri 21:58 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="generator" content="Org-mode"/>
<meta name="author" content="Ling Kun"/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012  Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Impala related notes</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. List</a></li>
<li><a href="#sec-2">2. The Design of Impala</a>
<ul>
<li><a href="#sec-2-1">2.1. Query Execution Overview</a></li>
<li><a href="#sec-2-2">2.2. Drawbacks</a></li>
</ul>
</li>
<li><a href="#sec-3">3. The Implementation of Impala</a>
<ul>
<li><a href="#sec-3-1">3.1. FE</a>
<ul>
<li><a href="#sec-3-1-1">3.1.1. Src/main/java/com/cloudera/impala/analysis</a></li>
<li><a href="#sec-3-1-2">3.1.2. Src/main/java/com/cloudera/impala/catalog</a></li>
<li><a href="#sec-3-1-3">3.1.3. Src/main/java/com/cloudera/impala/common</a></li>
<li><a href="#sec-3-1-4">3.1.4. Src/main/java/com/cloudera/impala/hive</a></li>
<li><a href="#sec-3-1-5">3.1.5. Src/main/java/com/cloudera/impala/planner</a></li>
<li><a href="#sec-3-1-6">3.1.6. Src/main/java/com/cloudera/impala/service</a></li>
</ul>
</li>
<li><a href="#sec-3-2">3.2. BE</a>
<ul>
<li><a href="#sec-3-2-1">3.2.1. Src/codegen</a></li>
<li><a href="#sec-3-2-2">3.2.2. Src/common:</a></li>
<li><a href="#sec-3-2-3">3.2.3. Src/exec</a></li>
<li><a href="#sec-3-2-4">3.2.4. Src/exprs/</a></li>
<li><a href="#sec-3-2-5">3.2.5. Src/runtime/</a></li>
<li><a href="#sec-3-2-6">3.2.6. Src/service/</a></li>
<li><a href="#sec-3-2-7">3.2.7. Src/statestore</a></li>
<li><a href="#sec-3-2-8">3.2.8. Src/testutil/</a></li>
<li><a href="#sec-3-2-9">3.2.9. Src/transport/</a></li>
<li><a href="#sec-3-2-10">3.2.10. Src/util/</a></li>
<li><a href="#sec-3-2-11">3.2.11. thirdparty</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sec-4">4. Impala Build on Debian Wheezy(7.0)</a>
<ul>
<li><a href="#sec-4-1">4.1. netdb.h: reference to 'addrinfo' is ambiguous</a></li>
<li><a href="#sec-4-2">4.2. bzlib.h: no such file or directory</a></li>
</ul>
</li>
<li><a href="#sec-5">5. Impala Runing on Debian Wheezy(7.0)</a>
<ul>
<li><a href="#sec-5-1">5.1. start-impalad.sh throw 'unsupported file system' error</a></li>
</ul>
</li>
<li><a href="#sec-6">6. Impala Links</a></li>
</ul>
</div>
</div>


<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> <span class="todo TODO">TODO</span> List</h2>
<div class="outline-text-2" id="text-1">
<p>
Get to know all the source code files, and why they are there.
Sort out all the TODOs in the source code file, and get a deep understand of what the authors plan to do for the next step
Get a better understand of the issues in the JIRA, so that I can know how they communicate with each other.
Solve the TODOs in this doc.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> The Design of Impala</h2>
<div class="outline-text-2" id="text-2">
<p>
Impala is an HDFS SQL execution engine. It provide support for interacting with very large data set.
</p>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> Query Execution Overview</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>Queries are submitted using Impala shell
</li>
<li>Impala distributed query engine builds and distributes the query plan across the cluster
</li>
<li>Every node reads data from HDFS or HBase locally. (Impalad - daemon which runs on data nodes and responds to impala shell)
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Drawbacks</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>Do not have fault tolerance within a query. If a node fails during the running of a query, the query have to be re-run
</li>
<li>Does not write the intermediate result to disk
</li>
<li>Does not support the following features/syntax which Hive supports:
<ul class="org-ul">
<li>DDLs
</li>
<li>XML
</li>
<li>JSON
</li>
</ul>
</li>
<li>No support for Serialization Deserialization. Can only read text files not custom binary files as of now.
</li>
<li>Does not support UDFs( User Defined functions)
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> The Implementation of Impala</h2>
<div class="outline-text-2" id="text-3">
<p>
Here is about Source Code Layout
</p>
</div>

<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> FE</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li><code>Src/main/jflex/sql-scanner.flex</code>
</li>
<li><code>Src/main/cup/sql-parser.y</code>
</li>
</ul>
</div>

<div id="outline-container-sec-3-1-1" class="outline-4">
<h4 id="sec-3-1-1"><span class="section-number-4">3.1.1</span> Src/main/java/com/cloudera/impala/analysis</h4>
<div class="outline-text-4" id="text-3-1-1">
<ul class="org-ul">
<li><code>AggregateExpr.java</code>:Extended from Expr. Class for Aggregate Expressions
</li>
<li>AggregateInfo.java: A Class Encapsulates all the information needed to compute the aggregate functions of a single Select block.
</li>
<li>AggregateParamsList.java: A Class of the Return value of the grammar production that parses aggregate function parameters.
</li>
<li>ParseNode.java: A interface for Node parse.
</li>
<li>ParseNodeBase.java: abstract class that implement the ParseNode interface, 
but for this base class, all the functions is implemented as null.
</li>
<li>AlterTableStmt.java: Abstract base Class for ALTER TABLE statements.
</li>
<li>AlterTableAddPartitionStmt.java: Abstract base for ALTER TABLE statements that work against Partition specs
</li>
<li>AlterTableAddReplaceColsStmt.java: Represents an ALTER TABLE ADD|REPLACE COLUMNS (colDef1, colDef2, …) statement.
</li>
<li>AlterTableChangeColStmt.java:Represents an ALTER TABLE CHANGE COLUMN colName newColDef statement. (have TODO in code)
</li>
<li>AlterTableDropColStmt.java: Represents an ALTER TABLE DROP COLUMN statement. Hive does not support, but supported by mysql
</li>
<li>AlterTablePartitionSpecStmt.java: Abstract base class for ALTER TABLE statements that work against Partition
</li>
<li>AlterTableDropPartitionStmt.java: Represents an ALTER TABLE DROP PARTITION statement.
</li>
<li>AlterTableRenameStmt.java: Represents an ALTER TABLE RENAME &lt;table&gt; statement.
</li>
<li>AlterTableSetFileFormatStmt.java: Represents an ALTER TABLE [PARTITION partitionSpec] SET FILEFORMAT statement.
</li>
<li>AlterTableSetLocationStmt.java:Represents an ALTER TABLE [PARTITION partitionSpec] SET LOCATION statement
</li>
<li>TableRef.java: An Abstract representation of a table reference. 
The actual table reference could be an inline view, or a base table, such as Hive table or HBase table.
</li>
<li>BaseTableRef.java: An actual table, such as HBase Table or a Hive Table.
</li>
<li>InlineViewRef.java: Inline view is a query statement with an alias.
</li>
<li>CreateDbStmt.java:Represent a CREATE DATABASE statement.
</li>
<li>CreateTableLikeStmt.java: Represent a CREATE TABLE LIKE statement which create 
a new table based on a copy of an existing table defination.
</li>
<li>CreateTableStmt.java: Represent a CREATE TABLE statement.
</li>
<li>DescribeStmt.java: Represent a DESCRIBE table statement.
</li>
<li>DropDbStmt.java: Represent a DROP [ IF EXISTS] DATABASE statement.
</li>
<li>DropTableStmt.java: Represent a DROP [IF EXISTS] TABLE statement.
</li>
<li>InsertStmt.java: Represent a single insert statement, include the select statement whose results are to be inserted.
</li>
<li>QueryStmt.java: Abstract base class of any statement that return results via a list of result expression.
</li>
<li>SelectStmt.java: Representation of a single select block, including GROUP BY, ORDER BY, and HIVING clause.
</li>
<li>UnionStmt.java: Representation of a union with its list of operands, and optional order by and limit.
</li>
<li>ShowDbStmt.java: Representation of a SHOW DATABASE [pattern] statement.
</li>
<li>ShowTableStmt.java: Representation of a SHOW TABLES [pattern] statement.
</li>
<li>UseStmt.java: Representation of a USE db statement.
</li>
<li>AnalysisContext.java: Wrapper class for parser and analyzer
</li>
<li>Analyzer.java: Repository of analysis state for single select block
</li>
<li>Expr.java: root of the expr node hierarchy, extened from TreeNode, ParseNode.
</li>
<li>ArithmeticExpr.java:
</li>
<li>Predicate.java:
</li>
<li>BetweenPredicate.java: Class describing between predicate.
</li>
<li>BinaryPredicate.java: Most predicates with two operands.
</li>
<li>CompoundPredicate.java: &amp;&amp;, ||, | predicate
</li>
<li>InPredicate.java:
</li>
<li>IsNullPredicate.java
</li>
<li>LikePredicate.java
</li>
<li>TupleIsNullPredicate.java: Internal expr that returns true if all of the given tuples are NULL, otherwise false
</li>
<li>LiteralExpr.java:
</li>
<li>BoolLiteral.java:
</li>
<li>DateLiteral.java:
</li>
<li>FloatLiteral.java:
</li>
<li>IntLiteral.java
</li>
<li>NullLiteral.java
</li>
<li>StringLiteral.java
</li>
<li>CaseExpr.java: represents the SQL expression CASE [expr] WHEN expr THEN expr [WHEN expr THEN expr …] [ELSE expr] END
</li>
<li>SlotRef.java:
</li>
<li>CastExpr.java:
</li>
<li>FunctionCallExpr.java:
</li>
<li>TimestampArithmeticExpr.java:Describe the addition and subtraction of time units from time stamps.
</li>
<li>CaseWhenClause.java: captures info of a single WHEN expr THEN expr clause.
</li>
<li>ColumnDef.java: Represents a column definition in a CREAT/ALTER TABLE statement(column name + data type) and optional comment.
</li>
<li>DescriptorTable.java: Repository for tuple ( and slot) descriptors.
</li>
<li>JoinOperator.java
</li>
<li>OpcodeRegistry.java: It provides a mapping between function signatures and opcodes.
The supported functions are code-gen'ed and added to the registry with an assigned opcode.
</li>
<li>OrderByElement.java: Combination of expr and ASC/DESC.
</li>
<li>PartitionKeyValue.java: Representation of a single column:value element in the PARTITION (…) clause of 
an insert or alter table statement.
</li>
<li>PartitionListItem.java: Representation of a single column:value element in the PARTITION (…) clause of 
an insert statement.
</li>
<li>SelectList.java: Select list items plus distinct clause.
</li>
<li>SelectListItem.java:
</li>
<li>SlotDescriptor.java:
</li>
<li>SlotId.java: Extended from com.cloudera.impala.common.Id
</li>
<li>ExprId.java: Extended from com.cloudera.impala.common.Id.
</li>
<li>TupleId.java
</li>
<li>SortInfo.java: Encapsulates all the information needed to compute ORDER BY.
</li>
<li>TableName.java
</li>
<li>TupleDescriptor.java
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-1-2" class="outline-4">
<h4 id="sec-3-1-2"><span class="section-number-4">3.1.2</span> Src/main/java/com/cloudera/impala/catalog</h4>
<div class="outline-text-4" id="text-3-1-2">
<ul class="org-ul">
<li>Catalog.java
</li>
<li>Column.java
</li>
<li>ColumnStats.java
</li>
<li>Db.java
</li>
<li>FileFormat.java
</li>
<li>HBaseColumn.java
</li>
<li>HBaseTable.java
</li>
<li>HdfsCompression.java
</li>
<li>HdfsFileFormat.java
</li>
<li>HdfsPartition.java
</li>
<li>HdfsStorageDescriptor.java
</li>
<li>HdfsTable.java
</li>
<li>HiveStorageDescriptorFactory.java
</li>
<li>InlineView.java
</li>
<li>PrimitiveType.java
</li>
<li>RowFormat.java
</li>
<li>Table.java
</li>
<li>TableId.java
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-1-3" class="outline-4">
<h4 id="sec-3-1-3"><span class="section-number-4">3.1.3</span> Src/main/java/com/cloudera/impala/common</h4>
<div class="outline-text-4" id="text-3-1-3">
<ul class="org-ul">
<li>AnalysisException.java
</li>
<li>Id.java
</li>
<li>IdGenerator.java
</li>
<li>ImpalaException.java
</li>
<li>ImpalaRuntimeException.java
</li>
<li>InternalException.java
</li>
<li>JniUtil.java
</li>
<li>MetaStoreClientPool.java
</li>
<li>NotImplementedException.java
</li>
<li>Pair.java
</li>
<li>Reference.java
</li>
<li>TreeNode.java
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-1-4" class="outline-4">
<h4 id="sec-3-1-4"><span class="section-number-4">3.1.4</span> Src/main/java/com/cloudera/impala/hive</h4>
<div class="outline-text-4" id="text-3-1-4">
<ul class="org-ul">
<li>Serde
</li>
<li>ParquetInputFormat.java
</li>
<li>ParquetOutputFormat.java
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-1-5" class="outline-4">
<h4 id="sec-3-1-5"><span class="section-number-4">3.1.5</span> Src/main/java/com/cloudera/impala/planner</h4>
<div class="outline-text-4" id="text-3-1-5">
<ul class="org-ul">
<li>AggregationNode.java
</li>
<li>DataPartition.java
</li>
<li>DataSink.java
</li>
<li>DataStreamSink.java
</li>
<li>ExchangeNode.java
</li>
<li>HashJoinNode.java
</li>
<li>HBaseScanNode.java
</li>
<li>HBaseTableSink.java
</li>
<li>HdfsScanNode.java
</li>
<li>HdfsTableSink.java
</li>
<li>MergeNode.java
</li>
<li>PlanFragment.java
</li>
<li>PlanFragmentId.java
</li>
<li>Planner.java
</li>
<li>PlanNode.java
</li>
<li>PlanNodeId.java
</li>
<li>ScanNode.java
</li>
<li>SelectNode.java
</li>
<li>SingleColumnFilter.java
</li>
<li>SortNode.java
</li>
<li>TableSink.java
</li>
<li>ValueRange.java
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-1-6" class="outline-4">
<h4 id="sec-3-1-6"><span class="section-number-4">3.1.6</span> Src/main/java/com/cloudera/impala/service</h4>
<div class="outline-text-4" id="text-3-1-6">
<ul class="org-ul">
<li>FeSupport.java
</li>
<li>Frontend.java
</li>
<li>JniFrontend.java
</li>
<li>MetadataOp.java
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> BE</h3>
<div class="outline-text-3" id="text-3-2">
</div><div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1"><span class="section-number-4">3.2.1</span> Src/codegen</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Use LLVM IR for CodeGen
</p>

<ul class="org-ul">
<li>llvm-codegen.cc/h: LLVM Code Generator. It is the top level object to generate jitted code.
</li>
<li>subexpr-elimination.cc/h: Optimization pass to remove redundant exprs.
</li>
<li>impala-ir.cc/h:Used to cross compile SQL to LLVM IR.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-2-2" class="outline-4">
<h4 id="sec-3-2-2"><span class="section-number-4">3.2.2</span> Src/common:</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>daemon.cc/h: an implementation of InitDaemon function.
</li>
<li>Global-flags.cc: Define some global flag strings,like hostname, be<sub>port</sub>, memory<sub>limit</sub>, etc.
</li>
<li>Global-types.h: introduce 4 id types: TupleId, SlotId, TableId, PlanNodeId.
</li>
<li>Hdfs.h:whether to include the hdfs.h, depends on whether the code is compiled to IR
</li>
<li>Logging.h: If already compiled to IR, we only use it, and not compile again.
</li>
<li>Object-pool.h: An objectPool maintains a list of C++ objects which are deallocated by destroying the pool.
</li>
<li>Status.cc/h:
</li>
<li>Compiler-util.h: Including some hint to compiler for branch likely optimization.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-2-3" class="outline-4">
<h4 id="sec-3-2-3"><span class="section-number-4">3.2.3</span> Src/exec</h4>
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li>aggregation-node.cc/h/-ir.cc：In-Memory Hash Aggregation(TODO:What is it), will aggregate output tuples and strings.
</li>
<li>base-sequence-scanner.cc/h: Super Class for all sequence container based file format, like SequenceFile, RCFile, Avro(TODO: what is these).
</li>
<li>hdfs-avro-scanner.cc/h: this scanner reads Avro object container files(ie, Avro data files) located in HDFS and writes the content as tuples in the Impala in-memory representation of data
</li>
<li>hdfs-rcfile-scanner.cc/h: a scanner to read RCFiles into tuples. (TODO: RCFile has a pseudo-BNF grammer)
</li>
<li>hdfs-sequence-scanner.cc/h: This scanner parses Sequence file located in HDFS, and writes the content as tuples in the Impala in-memory representation of data.
</li>
<li>data-sink.cc/h: Super Class for all data sinks, include Setup, Send, Close, CreateDataSink functions for DataSink usage.
</li>
<li>hbase-table-sink.cc/h: Class to take row batches and send them to the HBaseTableWriter to eventually be written into an HBase table.
</li>
<li>hdfs-table-sink.cc/h: The sink consumes all row batches of its child execution tree, and writes the evaluated output<sub>exprs</sub> into temporary Hdfs files. The query coordinator moves the temporary files into their final locations after the sinks have finished executing.
</li>
<li>ddl-executor.cc/h: Responsible for executing statements that modify or query table metadata explicitely.currently include SHOW and DESCRIBE statements, HiveServer2 metadata operations. Each query statement will typically have one DdlExecutor.
</li>
<li>delimited-text-parser.cc/h/.inline.h/-test.cc:The Delimited Text Parses text rows taht are delimited by specific chars. The main method is ParseData.
</li>
<li>exchange-node.cc/h: Receiver node for data stream. It simply feeds row batches received from the data stream into the execution tree.
</li>
<li>exec-node.cc/h: SupperClass of all executor nodes.
</li>
<li>merge-node.cc/h: Nodes that merges the results of its children by materializing their evaluated expressions into row batches. it pulls row batches sequentially from its children.
</li>
<li>scan-node.cc/h: Abstract base class of all scan node.
</li>
<li>hbase-scan-node.cc/h
</li>
<li>hdfs-scan-node.cc/h: A ScanNode implementation that is used for all tables read directly from HDFS-serialised data.
</li>
<li>select-node.cc/h: Node that evaluates conjuncts and enforces a limit but otherwise passes along the rows pulled from its child unchanged.
</li>
<li>topn-node.cc/h: Node for in-memory TopN (ORDER BY … LIMIT). This handles the case where the result fits in memory.
</li>
<li>hash-join-node.cc/h/-ir.cc: Node for in-memory hash joins.
</li>
<li>hash-table.cc/h/.inline.h/-test.cc: Hash table implementation designed for hash aggregation and hash joins. It store TupleRows and allows for different exprs for insertions and finds.
</li>
<li>hbase-table-scanner.cc/h: JNI wrapper class implementing minimal functionality for scanning an HBase table.
</li>
<li>hbase-table-writer.cc/h: Class to write RowBatches to an HBase table using the Java HTable Client.
</li>
<li>hdfs-lzo-text-scanner.cc/h: A wrapper for calling the external HdfsLzoTextScanner. The LZO scanner class is implemented in a dynamically linked library so that Impala does not include GPL code.
</li>
<li>hdfs-scanner.cc/h/-ir.cc: A superclass for different hdfs file format parsers. Each split has an instance of the scanner object, and each instance driven by a different thread created by the scan node.
</li>
<li>hdfs-parquet-scanner.cc/h: This scanner parses Parquet files located in HDFS, and writes the content as tuples in the Impala in-memory representation of data.( i.e. tuples, rows, row batches)
</li>
<li>hdfs-text-scanner.cc/h: HDFSScanner implementation that understands text-formatted records. (TODO: have SSE)
</li>
<li>hdfs-table-writer.cc/h: Pure virtual class for writing to HDFS table partition files. Subclasses implement the code needed to write to a specific file type.
</li>
<li>hdfs-parquet-table-writer.cc/h: the writter consumes all rows passed to it, and writes the evaluated output<sub>exprs</sub> as a parquet file in HDFS.
</li>
<li>hdfs-text-table-writer.cc/h: the writer consumes all rows passed to it and writes the evaluated output<sub>exprs</sub> as delimited text into Hdfs files.
</li>
<li>parquet-common.h: this file contains common elements between the parquet Writer and Scanner.
</li>
<li>read-write-util.cc/h: class for reading and writing various data types.
</li>
<li>scanner-context.cc/h/.inline.h: it encapsulates everything needed for hdfs scanners, and provides two main abstractions: a) abstraction of RowBatches and memory management. b) abstraction over getting buffers from the disk io mgr.
</li>
<li>sequence-file-recovery-test.cc: test file for sequence file??
</li>
<li>text-converter.cc/h/.inline.h: helper class for dealing with text data. e.g, converting text data to numeric types,etc.
</li>
<li>zigzag-test.cc: test file
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-2-4" class="outline-4">
<h4 id="sec-3-2-4"><span class="section-number-4">3.2.4</span> Src/exprs/</h4>
<div class="outline-text-4" id="text-3-2-4">
<p>
How the exprs in SQL is handled by Impala.
</p>

<ul class="org-ul">
<li>expr.cc/h/-ir.cc/-test.cc: superclass of all expr evaluation nodes
</li>
<li>agg-expr.cc/h: Aggregate Expr
</li>
<li>arithmetic-expr.cc/h
</li>
<li>case-expr.cc/h
</li>
<li>cast-expr.cc/h
</li>
<li>bool-literal.cc/h
</li>
<li>date-literal.cc/h
</li>
<li>float-literal.cc/h
</li>
<li>int-literal.cc/h
</li>
<li>null-literal.cc/h
</li>
<li>string-literal.cc/h
</li>
<li>timestamp-literal.cc/h
</li>
<li>function-call.cc/h
</li>
<li>predicate.h
</li>
<li>binary-predicate.cc/h
</li>
<li>compound-predicate.cc/h
</li>
<li>in-predicate.cc/h
</li>
<li>like-predicate.cc/h: The LIKE will be convered into the corresponding regular expression pattern.
</li>
<li>tuple-is-null-predicate.cc/h
</li>
<li>is-null-predicate.cc/h
</li>
<li>conditional-functions.cc/h
</li>
<li>math-functions.cc/h
</li>
<li>utility-functions.cc/h
</li>
<li>string-functions.cc/h
</li>
<li>timestamp-functions.cc/h
</li>
<li>opcode-registry.cc/h
</li>
<li>timezone<sub>db</sub>.cc: Time zone Database
</li>
<li>slot-ref.cc: Reference to a single slot of a tuple. the class is defined in expr.h
</li>
<li>expr-benchmark.cc: utility class to take (ascii) sql and return the plan.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-2-5" class="outline-4">
<h4 id="sec-3-2-5"><span class="section-number-4">3.2.5</span> Src/runtime/</h4>
<div class="outline-text-4" id="text-3-2-5">
<ul class="org-ul">
<li>client-cache.h/cc: Generic cache of Thrift clients for a given service type.
</li>
<li>coordinator.h/cc: Query coordinator is used to handle execution of plan fragments on remote nodes, given a TQueryExecRequest.
</li>
<li>data-stream-mgr.cc/h: Singleton class which manages all incoming data streams at a backend node. It provieds both producer and consumer functionality for each data steam.
</li>
<li>data-stream-recvr.h: Single receiver of an m:n data stream.
</li>
<li>data-stream-sender.cc/h: Single sender of an m:n data stream.
</li>
<li>data-stream-test.cc: Data Stream test code.
</li>
<li>descriptors.cc/h: Base class for table descriptors. Also defines HdfsTableDescriptor, HBaseTableDescriptor
</li>
<li>disk-io-mgr.cc/h/-test.cc: Manager object that schedules IO for all queires on all disks. Just like a multiple-producer-multiple-consumer problem.
</li>
<li>disk-io-mgr-stress.cc/h/-test.cc: Test utility to stress the disk io mgr
</li>
<li>exec-env.cc/h: Execution environment for queries/plan fragments. Contains all required global structures, and handles to singleton services.
</li>
<li>free-list.h/-test.cc: a free list made up of nodes which contain a pointer to the next node, and the size of the block.
</li>
<li>hbase-table.cc/h: Class to wrap JNI calls into HTable.
</li>
<li>hbase-table-factory.cc/h: A (process-wide) factory of HTable java objects. This object keeps java objects around to ease creation of HTables that share a pool of threads and connections.
</li>
<li>hdfs-fs-cache.cc/h: a (process-wide) cache of HdfsFS objects. These connections are shared across all threads and kept open until the process terminates.
</li>
<li>mem-limit.h: A MemLimit tracks memory consumption against a particular limit.
</li>
<li>mem-pool.cc/h/-test.cc: A MemPool maintains a list of memory chunks from which it allocates memory in response to Allocate() calls.
</li>
<li>parallel-executor.cc/h/-test.cc: A class that executes multiple functions in parallel with different arguments using a thread pool.
</li>
<li>plan-fragment-executor.cc/h: It handles all aspects of the execution of a single plan fragment, including setup and tear-down, both in the success and error case.
</li>
<li>primitive-type.cc/h
</li>
<li>raw-value.cc/h/-test.cc: Useful utility functions for runtime values( which are passed around as void*)
</li>
<li>row-batch.cc/h: a RowBatch encapsulates a batch of rows, each composed of a number of tuples.
</li>
<li>runtime-state.cc/h: A collection of items that are part of the global state of a query and shared across all execution nodes of that query.
</li>
<li>string-buffer.h/-test.cc: Implement a subset of std::string which support dynamic-sizable string, without as many copies and allocations.
</li>
<li>string-search.h: From Python, use boyer-moore-horspool algorithm to do substring search.
</li>
<li>string-value.cc/h/inline.h/-ir.cc/-test.cc: The returned StringValue of all functions that return StringValue shares its buffer the parent. (TODO: has SSE for strings compare)
</li>
<li>thread-resource-mgr.cc/h/-test.cc: Singleton(TODO: what is Singleton) object to manage CPU(aka (TODO what is aka) thread) resources for the process. Conceptually, there is a fixed pool of threads that are shared between query fragments.
</li>
<li>timestamp-value.cc/h/-test.cc: The format of a timestamp-typed slot.
</li>
<li>tuple.cc/h: a tuple is stored as a contiguous sequence of bytes containing a fixed number of fixed-size slots.
</li>
<li>tuple-row.cc/h: A TupleRow encapsulates a contiguous sequence of Tuple pointers which together make up a row.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-2-6" class="outline-4">
<h4 id="sec-3-2-6"><span class="section-number-4">3.2.6</span> Src/service/</h4>
<div class="outline-text-4" id="text-3-2-6">
<ul class="org-ul">
<li>fe-support.cc/h: The InitFeSupport() registers native functions with JNI, so that when Java function FeSupport.EvalPredicate is called within Impalad, the native implementation FeSupport<sub>EvalPredicateImpl</sub> already exists in Impalad binary.
</li>
<li>impala-server.cc/h: An ImpalaServer contains both frontend and backend functionality: it implements ImpalaService(Beeswax), ImpalaHiveServer2Service(HiveServer2) and ImpalaInternalService APIs.
</li>
<li>impala-beeswax-server.cc
</li>
<li>impala-hs2-server.cc
</li>
<li>impalad-main.cc: The main start point of Impalad. it will:
<ul class="org-ul">
<li>InitDaemon()
</li>
<li>LlvmCodeGen::InitializeLlvm()
</li>
<li>JniUtil::InitLibhdfs()
</li>
<li>JniUtil::Init()
</li>
<li>HBaseTableScanner::Init()
</li>
<li>HBaseTableFactory::Init()
</li>
<li>HBaseTableWriter::InitJNI()
</li>
<li>InitFeSupport()
</li>
<li>CreateImpalaServer()
</li>
<li>be<sub>server→Start</sub>();
</li>
<li>exec<sub>env</sub>.StartServices();
</li>
<li>beeswax<sub>server→Start</sub>();
</li>
<li>hs2<sub>server→Start</sub>()
</li>
<li>ImpaladMetrics::IMPALA<sub>SERVER</sub><sub>READY→Update</sub>(true)
</li>
<li>beeswax<sub>server→Join</sub>() (TODO: what is this used for)
</li>
<li>hs2<sub>server→Join</sub>()(TODO: what is this used for)
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-2-7" class="outline-4">
<h4 id="sec-3-2-7"><span class="section-number-4">3.2.7</span> Src/statestore</h4>
<div class="outline-text-4" id="text-3-2-7">
<ul class="org-ul">
<li>failure-detector.cc/h: A failure detector tracks the liveness of a set of peers which is computed as a function of received ‘heartbeat’ signals. There are four stattes for a peer: FAILED, SUSPECTED, OK, UNKNOWN.
</li>
<li>scheduler.h: Abstract scheduler and nameservice class. Given a list of resources and locations returns a list of hosts on which to execute plan fragments requiring those resources.
</li>
<li>simple-scheduler.cc/.h/-test.cc: Performs simple scheduling by matching between a list of hosts configured either from the state-store, or from a static list of addresses, and a list of target data locations.
</li>
<li>state-store.cc/h: It is a soft-state key-value store that maintains a set of Topics, which are maps from string keys to byte array value
</li>
<li>state-store-subscriber.cc/h: It communicates with a state-store periodically through the exchange of heartbeat messages. These messages contain updates from the state-store to a list of ‘topics’ that the subscriber is interested in ; in response the subscriber sends a list of changes that it wishes to make to a topic.
</li>
<li>statestored-main.cc: contains the main() function for a state store process which exports the Thrift service StateStoreService.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-2-8" class="outline-4">
<h4 id="sec-3-2-8"><span class="section-number-4">3.2.8</span> Src/testutil/</h4>
<div class="outline-text-4" id="text-3-2-8">
<ul class="org-ul">
<li>impalad-query-executor.cc/.h: Query execution against running impalad process.
</li>
<li>in-process-servers.cc/h: A single impala service, with a backend server, two client servers, a webserver and optionally a connection to a state-store.
</li>
<li>mini-impala-cluster.cc: A standalone test utility that starts multiple Impala backends and a state store within a single process.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-2-9" class="outline-4">
<h4 id="sec-3-2-9"><span class="section-number-4">3.2.9</span> Src/transport/</h4>
<div class="outline-text-4" id="text-3-2-9">
<p>
all the TSasl* file is used for Thrift, and plan to submitted to the upstream Thrift library.
</p>
<ul class="org-ul">
<li>config.h: Generted from configure.ac by autoheader
</li>
<li>TSasl.cpp/h:
</li>
<li>TSaslClientTransport.cpp/h
</li>
<li>TSaslServerTransport.cpp/h
</li>
<li>TSaslTransport.cpp/h
</li>
<li>undef.cpp
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-2-10" class="outline-4">
<h4 id="sec-3-2-10"><span class="section-number-4">3.2.10</span> Src/util/</h4>
<div class="outline-text-4" id="text-3-2-10">
<ul class="org-ul">
<li>authorization.cc/h: Routines to support Kerberos authentication through the thrift-sasl transport
</li>
<li>benchmark.cc/h/-test.cc: Utility class for microbenchmarks
</li>
<li>bit-stream-utils.h/.inline.h: Utility class to write bit/byte streams. It can write data to either be bit packed or byte aligned.
</li>
<li>bit-util.h/-test.cc: Utility class to do standard bit tricks
</li>
<li>buffer-builder.h: Utility class to build an in-memory buffer
</li>
<li>codec.cc/h: Create a compression object, and it is the base class for all compression algorithm.
</li>
<li>compress.cc/h: Another Compression class.
</li>
<li>container-util.h
</li>
<li>cpu-info.cc/h: An interface to query for CPU information at runtime.
</li>
<li>debug-counters.h: Runtime Counters have a two-phase life cycle: creation and update.
</li>
<li>debug-util.cc/.h/-test.cc: Contains some debug helpper function sand classes.
</li>
<li>decompress.cc/.h/-test.cc:
</li>
<li>default-path-handlers.cc/h Add a set of default path handlers to the webserver to display logs and configuration flags.
</li>
<li>disk-info.cc/h: An interface to query for the disk information at runtime, the information is pulled from /proc/partitions
</li>
<li>dynamic-util.cc/h: Dynamically linked library interfaces, which help lookup smybols.
</li>
<li>hash-util.cc/h/-ir.cc: the “ir” file defined the hashing functions for llvm
</li>
<li>hdfs-util.cc/h
</li>
<li>impalad-metrics.cc/h: Contains the keys for impala metrics.
</li>
<li>integer-array.cc/h/-test.cc: Helper class to extract integers of a fixed number of bits from an array.The ints are packed into sequential words in memroy.
</li>
<li>jni-util.cc/h: Utility class for JNI-related functionality.
</li>
<li>logging.cc/h: Utility for Google logging usage.
</li>
<li>mem-info.cc/h: Provides the amount of physical memory available, populated from /proc/meminfo.
</li>
<li>metrics.h/cc/-test.cc: : publishes execution metrics to a webserver pages
</li>
<li>TODO: reconsider naming here; metrics is too general.
</li>
<li>network-perf-benchmark.cc: A simple c/S network speed benchmakr utility. It can support send and broadcast benchmarks.
</li>
<li>network-util.cc/h: hostname related functions
</li>
<li>non-primitive-metrics.h: The metrics values whose value have more structure than simple primitive types.
</li>
<li>parquet-reader.cc
</li>
<li>parse-util.cc/h: Utility class for parsing information from strings.
</li>
<li>path-builder.cc/h: Utility class to construct full paths relative to the impala<sub>home</sub> path.
</li>
<li>perf-counters.cc/h/-test.cc: Utility class that aggregates counters from the kernel. like io, syscall, status
</li>
<li>progress-updater.cc/h: Utility class to update progress.
</li>
<li>refresh-catalog.cc: Simple utility to force planservice or impalad frontend to reload its catalog.
</li>
<li>rle-encoding.h: utility classes to do run length encoding(RLE) for fixed bit width values.
</li>
<li>rle-test.cc
</li>
<li>runtime-profile.cc/h/-test.cc: it is a group of profiling counters, it supports adding named counters and being able to serialize and deserialize them.
</li>
<li>sse-util.h: Contains constants useful for text procesing with SSE4.2 intrinsics.
</li>
<li>stat-util.h
</li>
<li>static-asserts.cc: Unused now.
</li>
<li>stopwatch.h: Utility class to measure time.
</li>
<li>string-parser.h: Utility functions for doing atoi/atof on non-null terminated strings.
</li>
<li>thrift-client.cc/h: Super class for templatized thrift clients.
</li>
<li>thrift-server.cc/h: Utility class for all thrift servers.
</li>
<li>thrift-util.cc/h/-test.cc: Utility class to serialize thrift objects to a binary format.
</li>
<li>uid-util.h
</li>
<li>url-coding.cc/h/-test.cc: Utility methods to URL-encoding, decoding.
</li>
<li>url-parser.cc/h
</li>
<li>webserver.cc/h:Wrapper class for the Mongoose web server library.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-2-11" class="outline-4">
<h4 id="sec-3-2-11"><span class="section-number-4">3.2.11</span> thirdparty</h4>
<div class="outline-text-4" id="text-3-2-11">
<ul class="org-ul">
<li>avro-1.7.1: a data serialization system(TODO: what is data serialization)
</li>
<li>cyrus-sasl-2.1.23: the Simple Authentication and Security Layer
</li>
<li>gflags-2.0: Command line flags module for C++.
</li>
<li>glog-0.3.2:Google log library, implement application-level logging.
</li>
<li>gperftools-2.0: Useful for developing multi-threaded applications in C++ with templates. It have TCMalloc, heap-checker, heap-profiler, and cpu-profiler.
</li>
<li>gtest-1.6.0: Google’s framework for writing C++ tests on a variety of platforms. Supports automatic test discovery, a rich set of assertions, user-defined assertions, death tests, fatal and non-fatal failures,…..
</li>
<li>hadoop-2.0.0
</li>
<li>mongoose: Easy to use web server.
</li>
<li>snappy-1.0.5: A compression/decompression library. Aiming for very high speeds and reasonable compression.
</li>
<li>thrift-0.9.0
</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Impala Build on Debian Wheezy(7.0)</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li><a href="https://github.com/cloudera/impala/blob/master/README.md">Official Impala Installation Guide</a>
</li>
</ul>
</div>


<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1"><span class="section-number-3">4.1</span> netdb.h: reference to 'addrinfo' is ambiguous</h3>
<div class="outline-text-3" id="text-4-1">
<p>
The full output of the problem:
</p>



<blockquote>
<p>
[  2%] Building CXX object be/src/common/CMakeFiles/Common.dir/status.cc.o
&#x2026;
In file included from impala-ir.cc:21:
In file included from /home/erlv/projects/databases/impala/be/src/exec/aggregation-node-ir.cc:19:
In file included from /home/erlv/projects/databases/impala/be/src/runtime/runtime-state.h:30:
In file included from /home/erlv/projects/databases/impala/be/src/runtime/exec-env.h:25:
In file included from /home/erlv/projects/databases/impala/be/src/runtime/client-cache.h:27:
In file included from /home/erlv/projects/databases/impala/be/src/util/thrift-client.h:29:
/home/erlv/projects/databases/impala/thirdparty/glog-0.3.2/src/glog/logging.h:472:9In file included from :impala-ir.cc: warning: 21:
In file included from /home/erlv/projects/databases/impala/be/src/exec/aggregation-node-ir.cc:19:
In file included from /home/erlv/projects/databases/impala/be/src/runtime/runtime-state.h:30:
In file included from /home/erlv/projects/databases/impala/be/src/runtime/exec-env.h:25:
In file included from /home/erlv/projects/databases/impala/be/src/runtime/client-cache.h:27:
In file included from /home/erlv/projects/databases/impala/be/src/util/thrift-client.h:33:
In file included from /home/erlv/projects/databases/impala/be/src/util/thrift-server.h:23:
In file included from /home/erlv/projects/databases/impala/thirdparty/thrift-0.9.0/build/include/thrift/server/TNonblockingServer.h:40:
In file included from /usr/include/event.h:57:
In file included from /usr/include/evutil.h:37:
In file included from /usr/include/event2/util.h:63:
<i>usr/include/netdb.h:587:16: error: reference to 'addrinfo' is ambiguous
  const struct addrinfo <b>ar<sub>request</sub>; /</b> Additional request specification.  *</i>
               ^
/usr/include/netdb.h:569:8: note: candidate found by name lookup is 'addrinfo'
struct addrinfo
       ^
/home/erlv/projects/databases/impala/thirdparty/thrift-0.9.0/build/include/thrift/transport/TSocket.h:244:30: note: candidate found by name
      lookup is 'apache::thrift::transport::addrinfo'
  void openConnection(struct addrinfo *res);
</p>
</blockquote>

<p>
Download Package from <a href="http://packages.ubuntu.com/precise/libevent1-dev">Ubuntu Package site</a>:
</p>
<ul class="org-ul">
<li>libevent
</li>
<li>libevent-core
</li>
<li>libevent-extra
</li>
<li>libevent-dev
</li>
</ul>

<p>
Use <code>dpkg -i</code> to install them. 
<b>Do not install the Debian default libevent-dev, it is v2.0, and does not support by thrift</b>
</p>


<p>
DONE!
</p>
</div>
</div>

<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2"><span class="section-number-3">4.2</span> bzlib.h: no such file or directory</h3>
<div class="outline-text-3" id="text-4-2">
<blockquote>
<p>
sudo apt-get install libbz2-dev 
</p>
</blockquote>

<p>
After install libbz2-dev, the problem is solved.
</p>

<p>
Done!
</p>
</div>
</div>
</div>


<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> Impala Runing on Debian Wheezy(7.0)</h2>
<div class="outline-text-2" id="text-5">
</div><div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1"><span class="section-number-3">5.1</span> start-impalad.sh throw 'unsupported file system' error</h3>
<div class="outline-text-3" id="text-5-1">
<p>
The error is as following:
</p>


<blockquote>
<p>
E0605 21:59:23.665810   772 impala-server.cc:648] Unsupported file system. Impala only supports DistributedFileSystem but the LocalFileSystem was found. fs.defaultFS(<a href="file:////">file:////</a>) might be set incorrectly
E0605 21:59:23.666024   772 impala-server.cc:650] Impala is aborted due to improper configurations.
</p>
</blockquote>
</div>
</div>
</div>


<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Impala Links</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li>Impala JIRA: <a href="https://issues.cloudera.org/browse/IMPALA">https://issues.cloudera.org/browse/IMPALA</a>
</li>
<li>Marcel Kornacker: <a href="http://www.linkedin.com/pub/marcel-kornacker/0/21/684">http://www.linkedin.com/pub/marcel-kornacker/0/21/684</a>
</li>
<li>Alexander Behm: <a href="http://www.ics.uci.edu/~abehm/">http://www.ics.uci.edu/~abehm/</a>
</li>
<li>Skye Wanderman-Milne: <a href="http://www.linkedin.com/pub/skye-wanderman-milne/29/87b/738">http://www.linkedin.com/pub/skye-wanderman-milne/29/87b/738</a>
</li>
<li>Lenni Kuff: <a href="http://www.linkedin.com/in/lskuff">http://www.linkedin.com/in/lskuff</a>
</li>
<li>Nong Li: <a href="http://www.linkedin.com/pub/nong-li/38/905/a1a">http://www.linkedin.com/pub/nong-li/38/905/a1a</a>
</li>
<li>Henry Robinson: <a href="http://www.linkedin.com/in/henrynrobinson">http://www.linkedin.com/in/henrynrobinson</a>
</li>
<li>Uri Laserson: <a href="http://www.linkedin.com/in/urilaserson">http://www.linkedin.com/in/urilaserson</a>
</li>
<li>Alan Choi: <a href="http://www.linkedin.com/pub/alan-choi/0/213/9a0">http://www.linkedin.com/pub/alan-choi/0/213/9a0</a>
</li>
<li>Hari Sekhon: <a href="http://www.linkedin.com/in/harisekhon">http://www.linkedin.com/in/harisekhon</a>
</li>
<li>Justin Erickson: <a href="http://www.linkedin.com/in/ericksonjustin">http://www.linkedin.com/in/ericksonjustin</a>
</li>
<li>Romain Rigaux: <a href="http://www.linkedin.com/in/romainrigaux">http://www.linkedin.com/in/romainrigaux</a>
</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Ling Kun</p>
<p class="date">Created: 2013-07-05 Fri 21:58</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 23.4.1 (<a href="http://orgmode.org">Org</a> mode 8.0.3)</p>
<p class="xhtml-validation"><a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a></p>
</div>
</body>
</html>
